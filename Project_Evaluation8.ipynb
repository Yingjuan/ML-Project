{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model For Predicting Movie Box Office Gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members: Ying Wu (A20370189), Yingjuan Wu (A20326320), Sahand Zeinali (A20318383)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description: \n",
    "In this project, we will explore the relationship between a movieâ€™s theatrical revenue and other key features. We will use worldwide box-office gross (numerical) as the target variable, and use relevant information that are available prior a movie's release as input variables, including general information like number of critic reviews, duration of movie (in mins), face number in poster, genres, budget, country, content-rating, imdb score, as well as social media factors like number of director facebook likes, number of cast total facebook likes, etc. \n",
    "\n",
    "The objective of this project is to build a regression model to predict movie box office gross. Categorical input variables include genres, country, and content-rating; numerical input variables are number of critic reviews, duration, face number in poster, budget, imdb score, number of director facebook likes, and number of cast total facebook likes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import dummy\n",
    "\n",
    "movies = pd.read_csv(\"Processed_Data.csv\", header = 0)\n",
    "original_headers = list(movies.columns.values)#save headers in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 87)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale continuous features to have 0 mean and 1 variance\n",
    "\n",
    "# num_critic_for_reviews\n",
    "movies['num_critic_for_reviews'] = preprocessing.scale(movies['num_critic_for_reviews'])\n",
    "# duration\n",
    "movies['duration'] = preprocessing.scale(movies['duration']) \n",
    "# director_facebook_likes\n",
    "movies['director_facebook_likes'] = preprocessing.scale(movies['director_facebook_likes']) \n",
    "# cast_total_facebook_likes\n",
    "movies['cast_total_facebook_likes'] = preprocessing.scale(movies['cast_total_facebook_likes']) \n",
    "# facenumber_in_poster\n",
    "movies['facenumber_in_poster'] = preprocessing.scale(movies['facenumber_in_poster']) \n",
    "# budget\n",
    "movies['budget'] = preprocessing.scale(movies['budget']) \n",
    "# imdb_score\n",
    "movies['imdb_score'] = preprocessing.scale(movies['imdb_score']) \n",
    "\n",
    "# Check the shape of data\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two measures to evaluate the performance of the regression models:\n",
    "\n",
    "1.Mean Squared Error(MSE) - measures the average of the squares of the errors. It is a risk function corresponding to the expected value of the squared error loss. We use 'neg_mean_squared_error' as scoring parameter in the cross-validation function to calculate the MSE scores.\n",
    "\n",
    "2.R^2 Score(Coefficient of Determination) - measures how well future instances are likely to be predicted by the model. The best possible score is 1. Higher R^2 score indicates better performance of regression model. We use 'r2_score' as scoring parameter in the cross-validation function to calculate the R^2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define target variable (gross) as target, define independent variables as data\n",
    "movies_array = movies.as_matrix()\n",
    "target = movies_array[:, 3]\n",
    "data = movies_array[:, list(range(0,3))+list(range(4,len(movies_array[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mean of target: 45608461.1575\n",
      "Actual mean of target: 45608461.1575\n",
      "Baseline MSE: 4.12674080594e+15\n",
      "Baseline R^2: -1.52339286602\n"
     ]
    }
   ],
   "source": [
    "#Baseline performance\n",
    "dum = dummy.DummyRegressor()\n",
    "dum.fit(data, target)\n",
    "pred_mean = np.mean(dum.predict(data))\n",
    "print(\"Predicted mean of target:\",pred_mean)\n",
    "print(\"Actual mean of target:\",np.mean(target))\n",
    "MSE_array = model_selection.cross_val_score(dum, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Baseline MSE:\",MSE)\n",
    "R2_array = model_selection.cross_val_score(dum, data, target, cv=10, scoring = 'r2')\n",
    "print(\"Baseline R^2:\",np.mean(R2_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Mean Squared Error (MSE) to measure the performance:\n",
      "Linear Regression with default settings:    MSE = 2.64367167074e+15  R^2 =  0.472313086101\n",
      "Linear Regression with fit_intercept=False: MSE = 2.64367407615e+15  R^2 =  0.472313086101\n",
      "Linear Regression with n_jobs=-1:           MSE = 2.64367167074e+15  R^2 =  0.472313086101\n",
      "Linear Regression with normalize=True:      MSE = 2.46248008551e+42  R^2 =  0.463866556306\n",
      "Linear Regression with false copy_X=False:  MSE = 1.71258839024e+35  R^2 =  0.32133367021\n"
     ]
    }
   ],
   "source": [
    "##Ordinary Least Squares Regression Model\n",
    "\n",
    "#Build model with default settings\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(data, target)\n",
    "#Use 10 fold cross-validation to calculate MSE\n",
    "MSE_array = model_selection.cross_val_score(reg, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "R2_array = model_selection.cross_val_score(reg, data, target, cv=10, scoring = 'r2')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Use Mean Squared Error (MSE) to measure the performance:\")\n",
    "print(\"Linear Regression with default settings:    MSE =\",MSE,\" R^2 = \",reg.score(data, target) )\n",
    "\n",
    "#Modify parameter fit_intercept\n",
    "reg1 = linear_model.LinearRegression(fit_intercept=False)\n",
    "reg1.fit(data, target)\n",
    "MSE1_array = model_selection.cross_val_score(reg1, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE1 = np.absolute(np.mean(MSE1_array))\n",
    "print(\"Linear Regression with fit_intercept=False: MSE =\",MSE1,\" R^2 = \",reg1.score(data, target) )\n",
    "\n",
    "#Modify parameter n_jobs\n",
    "reg4 = linear_model.LinearRegression(n_jobs=-1)\n",
    "reg4.fit(data, target)\n",
    "MSE4_array = model_selection.cross_val_score(reg4, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE4 = np.absolute(np.mean(MSE4_array))\n",
    "print(\"Linear Regression with n_jobs=-1:           MSE =\",MSE4,\" R^2 = \",reg4.score(data, target) )\n",
    "\n",
    "#Modify parameter normalize\n",
    "reg2 = linear_model.LinearRegression(normalize=True)\n",
    "reg2.fit(data, target)\n",
    "MSE2_array = model_selection.cross_val_score(reg2, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE2 = np.absolute(np.mean(MSE2_array))\n",
    "print(\"Linear Regression with normalize=True:      MSE =\",MSE2,\" R^2 = \",reg2.score(data, target) )\n",
    "\n",
    "#Modify parameter copy_X\n",
    "reg3 = linear_model.LinearRegression(copy_X=False)\n",
    "reg3.fit(data, target)\n",
    "MSE3_array = model_selection.cross_val_score(reg3, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE3 = np.absolute(np.mean(MSE3_array))\n",
    "print(\"Linear Regression with false copy_X=False:  MSE =\",MSE3,\" R^2 = \",reg3.score(data, target) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Mean Squared Error (MSE) and Coefficient of Determination (R^2) to measure the performance:\n",
      "Ridge Regression with default settings:    MSE =  2.46586966196e+15  R^2 =  0.47149245887\n",
      "Ridge Regression with alpha=0.5:           MSE =  2.49697052704e+15  R^2 =  0.471969734855\n",
      "Ridge Regression with fit_intercept=false: MSE =  2.46569305504e+15  R^2 =  0.471459488646\n",
      "Ridge Regression with solver='lsqr':       MSE =  2.44552892085e+15  R^2 =  0.469904512892\n"
     ]
    }
   ],
   "source": [
    "# Reset target and data, make sure data is not changed\n",
    "target = movies_array[:, 3]\n",
    "data = movies_array[:, list(range(0,3))+list(range(4,len(movies_array[0])))]\n",
    "\n",
    "# Ridge Regression Model\n",
    "\n",
    "# Default settings\n",
    "clf = linear_model.Ridge()\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Use Mean Squared Error (MSE) and Coefficient of Determination (R^2) to measure the performance:\")\n",
    "print(\"Ridge Regression with default settings:    MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# Modify parameter alpha, get best performance when alpha=0.5\n",
    "clf = linear_model.Ridge(alpha=0.5)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Ridge Regression with alpha=0.5:           MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# fit_intercept=false\n",
    "clf = linear_model.Ridge(fit_intercept=False)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Ridge Regression with fit_intercept=false: MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# Modify parameter solver, get best performance when solver='lsqr'\n",
    "clf = linear_model.Ridge(solver='lsqr')\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Ridge Regression with solver='lsqr':       MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Mean Squared Error (MSE) and Coefficient of Determination (R^2) to measure the performance:\n",
      "Bayesian Ridge Regression with default settings:           MSE =  4.12674080594e+15  R^2 =  9.30033827728e-13\n",
      "Bayesian Ridge Regression with Different alpha and lambda: MSE =  4.12674080591e+15  R^2 =  9.350520358e-12\n",
      "Bayesian Ridge Regression with fit_intercept=False:        MSE =  5.87417706621e+15  R^2 =  -0.547289862272\n",
      "Bayesian Ridge Regression with compute_score =True:        MSE =  4.12674080594e+15  R^2 =  9.30033827728e-13\n"
     ]
    }
   ],
   "source": [
    "# Reset target and data, make sure data is not changed\n",
    "target = movies_array[:, 3]\n",
    "data = movies_array[:, list(range(0,3))+list(range(4,len(movies_array[0])))]\n",
    "\n",
    "# Bayesian Ridge Regression Model\n",
    "\n",
    "# Default settings\n",
    "clf = linear_model.BayesianRidge()\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Use Mean Squared Error (MSE) and Coefficient of Determination (R^2) to measure the performance:\")\n",
    "print(\"Bayesian Ridge Regression with default settings:           MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# Different alpha and lambda\n",
    "clf = linear_model.BayesianRidge(alpha_1=1.e1, alpha_2=1.e2, lambda_1=1.e3, lambda_2=1.e4)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Bayesian Ridge Regression with Different alpha and lambda: MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# fit_intercept\n",
    "clf = linear_model.BayesianRidge(fit_intercept=False)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Bayesian Ridge Regression with fit_intercept=False:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# compute_score\n",
    "clf = linear_model.BayesianRidge(compute_score =True)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Bayesian Ridge Regression with compute_score =True:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with tol=1:      MSE =  2.53337154458e+15  R^2 =  0.458067873992\n",
      "Lasso with alpha=0.5:      MSE =  2.53337304789e+15  R^2 =  0.458067831135\n",
      "Lasso with normalize=True:        MSE =  2.53337154458e+15  R^2 =  0.458067873992\n",
      "Lasso with fit_intercept=False:        MSE =  2.75324351024e+15  R^2 =  0.391314906877\n",
      "Lasso with precomputer=True:        MSE =  2.53337154458e+15  R^2 =  0.458067873992\n",
      "Lasso with positive=True:        MSE =  2.49489904854e+15  R^2 =  0.441464092428\n",
      "Lasso with warm_start=True:        MSE =  2.53337154458e+15  R^2 =  0.458067873992\n",
      "Lasso with copy_X=False:        MSE =  2.53337154458e+15  R^2 =  0.177954146882\n"
     ]
    }
   ],
   "source": [
    "# Reset target and data, make sure data is not changed\n",
    "target = movies_array[:, 3]\n",
    "data = movies_array[:, list(range(0,3))+list(range(4,len(movies_array[0])))]\n",
    "\n",
    "# Lasso Regression Model\n",
    "\n",
    "#all the settings in Lasso Regression Model possess tol=1 since otherwise \n",
    "# Convergence Warnings were received\n",
    "\n",
    "# Default settings\n",
    "clf = linear_model.Lasso(tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with tol=1:      MSE = \",MSE,\" R^2 = \",clf.score(data, target))\n",
    "\n",
    "# alpha changed\n",
    "clf = linear_model.Lasso(alpha=0.5,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with alpha=0.5:      MSE = \",MSE,\" R^2 = \",clf.score(data, target))\n",
    "\n",
    "\n",
    "# normalize changed\n",
    "clf = linear_model.Lasso(fit_intercept=True,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with normalize=True:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "\n",
    "# fit_intercept changed\n",
    "clf = linear_model.Lasso(fit_intercept=False, tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with fit_intercept=False:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# precompute changed\n",
    "clf = linear_model.Lasso(precompute=True,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with precomputer=True:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# positive changed\n",
    "clf = linear_model.Lasso(positive=True,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with positive=True:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# warm_start changed\n",
    "clf = linear_model.Lasso(warm_start=True,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with warm_start=True:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n",
    "# copy_X changed\n",
    "clf = linear_model.Lasso(copy_X=False,tol=1)\n",
    "clf.fit(data, target) \n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Lasso with copy_X=False:        MSE = \",MSE,\" R^2 = \",clf.score(data, target) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of best model: MSE = 2.4455338374e+15  R^2 =  0.469904512892\n",
      "Feature # 1     Japan  (Weight: -55841237.3165 )\n",
      "Feature # 2     USA  (Weight: 30814705.9574 )\n",
      "Feature # 3     Hungary  (Weight: -27750059.7128 )\n",
      "Feature # 4     Documentary  (Weight: -20355670.4002 )\n",
      "Feature # 5     Animation  (Weight: 20166026.9034 )\n",
      "Feature # 6     num_critic_for_reviews  (Weight: 19990562.8122 )\n",
      "Feature # 7     Family  (Weight: 19939213.7658 )\n",
      "Feature # 8     Drama  (Weight: -18989489.516 )\n",
      "Feature # 9     West Germany  (Weight: -18708252.9169 )\n",
      "Feature # 10     Canada  (Weight: 18471238.6345 )\n"
     ]
    }
   ],
   "source": [
    "# After reviewing all the models, we found Ridge regression model with solver set to \n",
    "#'lsqr'performs the best.\n",
    "# Therefore, we choose Ridge regression model and report the feature importance.\n",
    "\n",
    "target = movies_array[:, 3]\n",
    "data = movies_array[:, list(range(0,3))+list(range(4,len(movies_array[0])))]\n",
    "clf = linear_model.Ridge(solver='lsqr')\n",
    "clf.fit(data, target)\n",
    "MSE_array = model_selection.cross_val_score(clf, data, target, cv=10, scoring = 'neg_mean_squared_error')\n",
    "MSE = np.absolute(np.mean(MSE_array))\n",
    "print(\"Performance of best model: MSE =\",MSE,\" R^2 = \",clf.score(data, target))\n",
    "\n",
    "\n",
    "# Report Important Features\n",
    "# Align feature with its name\n",
    "data_name = list(movies.columns.values)\n",
    "del data_name[3]\n",
    "features = zip(clf.coef_, data_name)\n",
    "\n",
    "# Sort features according to the absolute value of their weights\n",
    "features = sorted(features, key = lambda x:-np.abs(x[0]))\n",
    "\n",
    "# Print out the top ten features\n",
    "for i in range(0,10):\n",
    "    print(\"Feature #\",i+1,\"   \",features[i][1],\" (Weight:\",features[i][0],\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
